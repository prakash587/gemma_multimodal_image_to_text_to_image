# ğŸ§  Multimodal Streamlit App â€” Text â†” Image (Local + Hugging Face)

A lightweight, **low-VRAM** multimodal AI app built with **Streamlit**, **Hugging Face Diffusers**, and **Ollamaâ€™s LLaVA** model.  
Generate **images from text** (Stable Diffusion Turbo) and **describe images** (LLaVA) â€” all locally, GPU-optimized, and secure. ğŸš€

---

## âš™ï¸ Features

ğŸ”¹ **Text â†’ Image:** Uses `stabilityai/sd-turbo` from Hugging Face.  
ğŸ”¹ **Image â†’ Text:** Powered by Ollamaâ€™s `llava:latest` model.  
ğŸ”¹ **Low VRAM Support:** Works with GPUs like GTX 1650 (uses float32 and CPU offload).  
ğŸ”¹ **Local + Secure:** Keeps API keys in `.streamlit/secrets.toml`, not in code.  
ğŸ”¹ **Streamlit UI:** Simple, interactive two-tab interface.

---

## Configure Hugging Face Token
.streamlit/secrets.toml
[hf]
token = "hf_your_actual_token_here"



## ğŸ§© Requirements

- Python **3.10** or higher  
- GPU with CUDA (recommended)  
- [Ollama](https://ollama.com/download) installed and `llava` model pulled  
- Hugging Face account + access token  
- Git

---

## ğŸ“¦ Setup Instructions

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/<your-repo-name>.git
cd <your-repo-name>
